{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBlRKyFVXlZ5N9Z7W5b1vV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cgN77/opinion_mining/blob/main/TweetStuff_NaiveBayes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tweet Stuff\n"
      ],
      "metadata": {
        "id": "n7B-7pIdyyTv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HaZDv1oYys3m"
      },
      "outputs": [],
      "source": [
        "import pdb\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import string\n",
        "from nltk.tokenize import TweetTokenizer\n",
        "from os import getcwd\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "# import streamlit as st"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "filePath = f\"{getcwd()}/../tmp2/\"\n",
        "nltk.data.path.append(filePath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azam36K1y7kp",
        "outputId": "fa6fd0d2-78a7-45e5-8e21-a47511815d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "all_negative_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "test_pos = all_positive_tweets[4000:]\n",
        "train_pos = all_positive_tweets[:4000]\n",
        "test_neg = all_negative_tweets[4000:]\n",
        "train_neg = all_negative_tweets[:4000]\n",
        "\n",
        "train_x = train_pos + train_neg\n",
        "test_x = test_pos + test_neg\n",
        "\n",
        "train_y = np.append(np.ones(len(train_pos)), np.zeros(len(train_neg)))\n",
        "test_y = np.append(np.ones(len(test_pos)), np.zeros(len(test_neg)))\n",
        "len(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tm03pc_lzlSo",
        "outputId": "14e79e9e-4316-4cf5-d389-4d2af6f3e6ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer = PorterStemmer()\n",
        "def stem_words(words):\n",
        "    return [stemmer.stem(word) for word in words]\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_words(text):\n",
        "  # words = text.split()\n",
        "  return [lemmatizer.lemmatize(word) for word in text]"
      ],
      "metadata": {
        "id": "sw3cVeaPzyFi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tweet processing"
      ],
      "metadata": {
        "id": "7qIPFYJI0b4M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tw = \"@FindBenNeedham it's my birthday today so for my birthday wish I hope there's good news about Ben soon :-)\"\n",
        "\n",
        "url_pattern = re.compile(r'https?://\\S+')\n",
        "# happy_emoticon=r':)'\n",
        "# sad_emoticon=r':('\n",
        "\n",
        "def remove_urls(text):\n",
        "    return url_pattern.sub('', text)\n",
        "\n",
        "def separate_common_word(compound_word, common_word):\n",
        "    if common_word in compound_word:\n",
        "        base_word, rest_of_word = compound_word.split(common_word, 1)\n",
        "        return base_word+' '+common_word + rest_of_word\n",
        "    else:\n",
        "        return compound_word\n",
        "\n",
        "def process_tweet(tweet):\n",
        "  tweet=tweet.replace(':)','happyemoticon')\n",
        "  tweet=separate_common_word(tweet,'happyemoticon')\n",
        "  tweet=tweet.replace(':(','sademoticon')\n",
        "  tweet=separate_common_word(tweet,'sademoticon')\n",
        "  tweet=tweet.replace(':-)','happyemoticonwithnose')\n",
        "  tweet=separate_common_word(tweet,'happyemoticonwithnose')\n",
        "  tweet=tweet.replace(':-(','sademoticonwithnose')\n",
        "  tweet=separate_common_word(tweet,'sademoticonwithnose')\n",
        "  tweet=tweet.lower()\n",
        "  tweet=separate_common_word(tweet,'d')\n",
        "  tweet=remove_urls(tweet)\n",
        "  tweet = re.sub(r'[^\\w\\s]', '', tweet)\n",
        "  tweet=re.sub(r'\\d','',tweet)\n",
        "  tweet=word_tokenize(tweet)\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  tweet = [word for word in tweet if word.lower() not in stop_words]\n",
        "  tweet=stem_words(tweet)\n",
        "  tweet=lemmatize_words(tweet)\n",
        "  return tweet\n",
        "\n",
        "tw=process_tweet(tw)\n",
        "tw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cnGFXdL0Get",
        "outputId": "53a9968e-b3d8-4346-e21b-75e8ba697825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['fin',\n",
              " 'dbenneedham',\n",
              " 'birthday',\n",
              " 'today',\n",
              " 'birthday',\n",
              " 'wish',\n",
              " 'hope',\n",
              " 'there',\n",
              " 'good',\n",
              " 'news',\n",
              " 'ben',\n",
              " 'soon',\n",
              " 'happyemoticonwithnos']"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counting words"
      ],
      "metadata": {
        "id": "CIAbc_0K0mDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_tweets(result,tweets,ys):\n",
        "  for y,tweet in zip(ys,tweets):\n",
        "    for word in process_tweet(tweet):\n",
        "      pair=(word,y)\n",
        "      if pair in result:\n",
        "        result[pair]+=1\n",
        "      else:\n",
        "        result[pair]=1\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "CIveDnGa0Y3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = {}\n",
        "tweets = ['i am happy', 'i am tricked', 'i am sad', 'i am tired', 'i am tired']\n",
        "y = [1, 0, 0, 0, 0]\n",
        "count_tweets(result, tweets, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obJSG7Aa0uAi",
        "outputId": "d17ecc38-3b10-4476-f4e1-dc1c6e2762d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{('happi', 1): 1, ('trick', 0): 1, ('sa', 0): 1, ('tire', 0): 2}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frequencies = count_tweets({}, train_x, train_y)\n",
        "frequencies[('happi',1)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbDg8Q5j0-W5",
        "outputId": "08d5e8cd-0dd9-494a-f08c-b84f7b105085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "161"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lookup(freqs,word,n):\n",
        "  if (word,n) in freqs.keys():\n",
        "    return freqs[(word,n)]\n",
        "  return 0\n",
        "lookup(frequencies,'town',1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NApe3FsbAG_0",
        "outputId": "41f2451d-0c7f-493e-e533-5675d3634605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_naive_bayes(frequencies,train_x,train_y):\n",
        "  log_likelihood={}\n",
        "  logprior=0\n",
        "\n",
        "  vocab=set([pair[0] for pair in frequencies.keys()])\n",
        "  v=len(vocab)\n",
        "\n",
        "  Npos=Nneg=0\n",
        "  for pair in frequencies.keys():\n",
        "    if pair[1]>0:\n",
        "      Npos+=frequencies[pair]\n",
        "    else:\n",
        "      Nneg+=frequencies[pair]\n",
        "\n",
        "  D=len(train_y)\n",
        "  Dpos=np.sum(train_y)\n",
        "  Dneg=D-Dpos\n",
        "  logprior=np.log(Dpos)-np.log(Dneg)\n",
        "\n",
        "  for word in vocab:\n",
        "    freq_pos=lookup(frequencies,word,1)\n",
        "    freq_neg=lookup(frequencies,word,0)\n",
        "\n",
        "    pwpos=(freq_pos+1)/(Npos+v)\n",
        "    pwneg=(freq_neg+1)/(Nneg+v)\n",
        "\n",
        "    log_likelihood[word]=np.log(pwpos/pwneg)\n",
        "\n",
        "  return logprior,log_likelihood\n"
      ],
      "metadata": {
        "id": "q-mi9lbI3Knh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logprior,log_likelihood=train_naive_bayes(frequencies,train_x,train_y)\n",
        "log_likelihood"
      ],
      "metadata": {
        "id": "ZyAVgnGUAPqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def naive_bayes_predict(tweet,logprior,log_likelihood):\n",
        "  tweet=process_tweet(tweet)\n",
        "  result=0\n",
        "  for word in tweet:\n",
        "    if word in log_likelihood.keys():\n",
        "      result+=log_likelihood[word]\n",
        "    else:\n",
        "      result+=0\n",
        "  result+=logprior\n",
        "  return result"
      ],
      "metadata": {
        "id": "Om1MvDcCFIgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t='i love this product'\n",
        "naive_bayes_predict(t,logprior,log_likelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HU33wsHGH_MT",
        "outputId": "9caf958e-ecb2-4b54-e100-feccc859e25a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.327016704823454"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for tweet in ['I am happy', 'I am bad', 'this movie should have been great.', 'great']:\n",
        "  p = naive_bayes_predict(tweet, logprior, log_likelihood)\n",
        "  print(f'{tweet} -> {p:.2f}')\n",
        "my_tweet = 'you are bad :('\n",
        "naive_bayes_predict(my_tweet, logprior, log_likelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S261pje8Xg5Z",
        "outputId": "5ff3f057-49df-4830-9f7e-8474dc06a21c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I am happy -> 2.13\n",
            "I am bad -> -1.03\n",
            "this movie should have been great. -> 2.28\n",
            "great -> 2.13\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-8.797732393495618"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Truth Predicted Tweet')\n",
        "for x, y in zip(test_x, test_y):\n",
        "    y_hat = naive_bayes_predict(x, logprior, log_likelihood)\n",
        "    if y != (np.sign(y_hat) > 0):\n",
        "        print('%d\\t%0.2f\\t%s' % (y, np.sign(y_hat) > 0, ' '.join(\n",
        "            process_tweet(x)).encode('ascii', 'ignore')))"
      ],
      "metadata": {
        "id": "SmQCyfohusaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(test_x, test_y, logprior, log_likelihood):\n",
        "    y_pred=[]\n",
        "    l=[]\n",
        "    for tweet,y in zip(test_x, test_y):\n",
        "        prediction = 1 if naive_bayes_predict(tweet, logprior, log_likelihood) > 0 else 0\n",
        "        y_pred.append(prediction)\n",
        "        l.append(1 if prediction==y else 0)\n",
        "    return np.sum(l)/len(l)*100"
      ],
      "metadata": {
        "id": "IOjqvdTtxyh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(test_x,test_y,logprior,log_likelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hrizzmttysBo",
        "outputId": "e6e63dd3-96db-4537-cfb3-99f4bc19e14e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "97.2"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tweet='i am good :)'\n",
        "x=naive_bayes_predict(tweet,logprior,log_likelihood)\n",
        "if x>1:\n",
        "    print(':)')\n",
        "elif x<1 and x>-1:\n",
        "    print(':|')\n",
        "else:\n",
        "    print(':(')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KLEnoWJf0991",
        "outputId": "f23fb173-6b94-44e1-8f2c-67b0520cc00b"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ":)\n"
          ]
        }
      ]
    }
  ]
}